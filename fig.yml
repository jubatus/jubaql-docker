# To demo JubaQL to a full extent, we need a Hadoop/HDFS/YARN cluster
# and a Kafka queue. Also, we need data in these sources, so we also
# add a fluentd container to pipe data into HDFS and Kafka.

# Kafka needs a Zookeeper instance. This does not need much configuring,
# so we just take a standard image.
zookeeper:
  image: jplock/zookeeper

# Run Kafka using the Zookeeper instance above. This does not need much
# configuring, so we just take a standard image.
# (Kafka executables are in /opt/kafka_2.8.0-0.8.1.1/bin.)
kafka:
  image: wurstmeister/kafka:0.8.1.1-1
  # Use the above zookeeper container:
  links:
  - zookeeper:zk
  # Run on the standard port 9092 and create new topics with
  # 10 partitions by default.
  environment:
    KAFKA_ADVERTISED_PORT: 9092
    KAFKA_NUM_PARTITIONS: 10
  # If we don't set the hostname here, the `hostname` command run in
  # the container will return the container's id, which cannot be looked
  # up from other containers. This will confuse fluentd. Therefore we
  # set the hostname explicitly:
  hostname: kafka

# Hadoop/HDFS/YARN container based on sequenceiq/hadoop-docker:2.6.0.
# (Hadoop executables are in /usr/local/hadoop/bin.) Since we need
# to install Jubatus, add JubatusOnYARN files to HDFS and add some
# custom configuration, we will extend the image.
hdpnode:
  # Use the Dockerfile from the `hadoop/` directory.
  build: hadoop
  # This node will also run the JubaQL Processor instances (so we
  # need access to Kafka) and the Jubatus instances (so we need
  # access to a Zookeeper instance):
  links:
  - zookeeper:zk
  - kafka:kafka
  # If we don't set the hostname here, the `hostname` command run in
  # the container will return the container's id, which cannot be looked
  # up from other containers. This will confuse fluentd. Therefore we
  # set the hostname explicitly:
  hostname: hdpnode

# fluentd container based on jplock/fluentd:1.1.20. (fluentd
# executables are in /usr/lib/fluent/ruby/bin.) Since we need to
# install additional modules and add some custom configuration, we
# will extend the image.
fluentd:
  # Use the Dockerfile from the `fluentd/` directory.
  build: fluentd
  # This node will write to HDFS and Kafka, so it needs to access
  # both of those containers.
  links:
  - hdpnode:hdpnode
  - kafka:kafka

# JubaQL Server container based on phusion/baseimage:0.9.16.
jubaql:
  # Use the Dockerfile from the `jubaql/` directory.
  build: jubaql
  # This node will submit YARN jobs, so it needs to access the
  # Hadoop container.
  links:
  - hdpnode:hdpnode
